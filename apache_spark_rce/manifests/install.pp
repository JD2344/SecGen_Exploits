# Class: apache_spark_rce::install
# install process
#
class apache_spark_rce::install {
  Exec { path => [ '/bin/', '/sbin/' , '/usr/bin/', '/usr/sbin/' ] }

  # Install required packages
  # NOTE: once Debian updates insert scala 2.12+ into statement
  ensure_packages(['openjdk-11-jdk'], { ensure => 'installed'})

  $scaladeb = 'scala-2.12.10.deb'
  # We run older versions of debian, for now source from local deb file
  package { 'scala':
    ensure   => latest,
    provider => apt,
    source   => "/tmp/${scaladeb}",
  }

  $releasename = 'spark-3.1.2-bin-hadoop3.2'
  file { "/tmp/${releasename}.tgz":
    ensure => file,
    source => "puppet:///modules/apache_spark_rce/${releasename}.tgz"
  }
  -> file { "/tmp/${scaladeb}":
    ensure => file,
    source => "puppet:///modules/apache_spark_rce/${scaladeb}"
  }
  -> exec { 'unpack-spark':
    cwd     => '/tmp',
    command => "tar -xf ${releasename}.tgz",
    creates => '/tmp/spark'
  }
  -> exec { 'move-spark':
    cwd     => '/tmp',
    command => "mv /tmp/${releasename} /usr/local/spark/",
    creates => '/usr/local/spark',
  }
}
