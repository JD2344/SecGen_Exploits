# Class: apache_spark_rce
# apache_spark_install
#
class apache_spark_rce::install {
  Exec { path => [ '/bin/', '/sbin/' , '/usr/bin/', '/usr/sbin/' ] }

  # Install required packages
  ensure_packages(['openjdk-11-jdk'], { ensure => 'installed'})

  # TODO: FIND proper way of getting spark to persist. 
  $releasename = 'spark-3.1.2-bin-hadoop3.2.tgz'
  $scaladeb = 'scala-2.12.10.deb'
  file { "/tmp/${releasename}":
    ensure => file,
    source => "puppet:///modules/apache_spark_rce/${releasename}"
  }
  -> file { "/tmp/${scaladeb}":
    ensure => file,
    source => "puppet:///modules/apache_spark_rce/${releasename}"
  }
  -> exec { 'unpack-spark':
    cwd     => '/tmp',
    command => "tar -xf ${releasename}",
    creates => '/tmp/spark'
  }
  -> exec { 'move-spark':
    cwd     => '/tmp',
    command => 'mv /tmp/spark /usr/local/spark',
    creates => '/usr/local/spark',
  }
  -> exec { 'set-spark-path-env':
    cwd     => '~/',
    command => "echo 'export PATH=${PATH}:/usr/local/spark/bin' >> ~/.bashrc",
  }
  -> exec { 'spark-set-acls':
    cwd     => '/usr/local/spark/conf/',
    command => 'echo "spark.acls.enable true" >> /usr/local/spark/conf/spark-defaults.conf',
  }
  -> exec { 'install-scala-deb':
    cwd     => '/tmp',
    command => "apt install ${scaladeb}",
    creates => '/usr/bin/scala',
  }
}
